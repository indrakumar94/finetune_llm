{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2801970-3a3d-43dc-b331-4ab632a8abf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indrakumar/projects/gradio_demo/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6517f3-dba4-46f6-8860-3ba01adc7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name):\n",
    "    return \"Hello \" + name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541af410-b8a0-4711-8717-0c69e8f7fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff24016-132e-4947-a792-ba6bc65d000f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f72fd89-e4d3-4c35-8ffc-13ecffba548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "textbox = gr.Textbox(label=\"Type your name here:\", placeholder=\"John Doe\", lines=5)\n",
    "output_textbox = gr.Textbox(label=\"Output Here\", placeholder=\"Hello John Doe\", lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "398c4dbc-8917-4d05-9be0-b6531e48d688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=greet, inputs=textbox, outputs=output_textbox).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba8e93a-4796-4147-b895-346e9f3a1cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.2.2-cp38-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp38-cp38-macosx_10_13_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.2.2-cp38-cp38-macosx_10_13_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.8/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.8/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.8/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.8/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.2.2-cp38-none-macosx_10_9_x86_64.whl (150.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 MB\u001b[0m \u001b[31m861.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.17.2-cp38-cp38-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.2.2-cp38-cp38-macosx_10_13_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Downloading sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m784.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, torch, torchvision, torchaudio\n",
      "Successfully installed mpmath-1.3.0 networkx-3.1 sympy-1.13.2 torch-2.2.2 torchaudio-2.2.2 torchvision-0.17.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd3f1f4e-388e-4a97-afa6-d78e7d33d606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.44.1-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./venv/lib/python3.8/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./venv/lib/python3.8/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.8/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.8/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.7.24-cp38-cp38-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in ./venv/lib/python3.8/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.4-cp38-cp38-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Using cached tokenizers-0.19.1-cp38-cp38-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.8/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.8/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.8/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.8/site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.44.1-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m785.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.7.24-cp38-cp38-macosx_10_9_x86_64.whl (282 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.3/282.3 kB\u001b[0m \u001b[31m900.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.4-cp38-cp38-macosx_10_12_x86_64.whl (393 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached tokenizers-0.19.1-cp38-cp38-macosx_10_12_x86_64.whl (2.5 MB)\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.7.24 safetensors-0.4.4 tokenizers-0.19.1 transformers-4.44.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0600a562-c3eb-4049-b93c-c90ecc1abb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2517bc53-d20c-4dfd-861f-14392027da5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/indrakumar/projects/gradio_demo/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "model = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d032119-da93-4b6f-88ce-c8a75b6381dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt):\n",
    "    completion = model(prompt)[0][\"generated_text\"]\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbf1aac5-be2f-40ce-8ac8-83b6708bdf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"My favorite programming language is a good way to start out. I'll get you started with it and show you how to get started.\\n\\nThe next time you're working from home, don't even think about it before saying that this is your\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"My favorite programming language is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4efead0d-c189-4c8b-b609-8039eed3c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "gr.Interface(fn=predict, inputs=\"text\", outputs=\"text\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "324b8138-4346-46a2-b0f4-156e53f227ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f731219b-5e6e-41ba-9a8d-f0e5cb0cce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_audio(audio):\n",
    "    sr, data = audio\n",
    "    reversed_audio = (sr, np.flipud(data))\n",
    "    return reversed_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1af8218-4a0e-42e3-a22d-e3af8ea9233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = gr.Audio(sources=\"microphone\", type=\"numpy\", label=\"Speak here...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eb599e8-ff28-444f-9476-b1ac94afc5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(reverse_audio, mic, \"audio\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5ccacd7-9f05-4f24-aef0-9e1fb12946eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d20ccdd-ec26-4b9c-b683-25fa11133086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio):\n",
    "    sr, y = audio\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63100d92-1bcd-4de5-813b-f36e9fb88685",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    gr.Audio(sources=[\"microphone\"]),\n",
    "    \"text\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13853ee3-9dbc-4173-84c9-1bbfa428854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indrakumar/projects/gradio_demo/venv/lib/python3.8/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4431bf-8a17-4594-bd8d-af0fa50f4e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
